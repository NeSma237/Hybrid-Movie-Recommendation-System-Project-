{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeSma237/Hybrid-Movie-Recommendation-System-Project-/blob/main/Hybrid_Movie_Recommendation_Sysem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llwhDfHSzyrs",
        "outputId": "28cb0189-a0ee-4b5f-bfe0-e9601f1fc844"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8FryjX2zw-7",
        "outputId": "1710f11e-f35b-4f68-940f-da6d2ab29bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-21 18:46:37.012 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.017 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.021 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.026 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.035 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.039 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.043 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.047 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.050 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-21 18:46:37.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "\n",
        "# Load data\n",
        "movies = pd.read_csv(\"movies.csv\")\n",
        "ratings = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Split ratings into training (80%) and testing (20%)\n",
        "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF for content-based filtering\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "movies['genres'] = movies['genres'].fillna('')\n",
        "tfidf_matrix = tfidf.fit_transform(movies['genres'])\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()\n",
        "\n",
        "# Create rating matrix from training data\n",
        "rating_matrix = train_data.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Collaborative Filtering using SVD\n",
        "svd = TruncatedSVD(n_components=20)\n",
        "svd_matrix = svd.fit_transform(rating_matrix)\n",
        "predicted_ratings = np.dot(svd_matrix, svd.components_)\n",
        "\n",
        "movie_ids = rating_matrix.columns\n",
        "user_ids = rating_matrix.index\n",
        "\n",
        "# ================== Recommendation Functions ==================\n",
        "\n",
        "def get_content_recommendations(title, top_n=10):\n",
        "    idx = indices.get(title)\n",
        "    if idx is None:\n",
        "        return pd.DataFrame({'Error': ['Movie not found.']})\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return movies.iloc[movie_indices][['movieId', 'title']].assign(score=[round(s[1], 4) for s in sim_scores])\n",
        "\n",
        "def get_collab_recommendations(user_id, top_n=10):\n",
        "    if user_id not in user_ids:\n",
        "        return pd.DataFrame({'Error': ['User ID not found.']})\n",
        "    user_idx = list(user_ids).index(user_id)\n",
        "    user_ratings = predicted_ratings[user_idx]\n",
        "    top_indices = user_ratings.argsort()[::-1][:top_n]\n",
        "    top_movie_ids = movie_ids[top_indices]\n",
        "    results = movies[movies['movieId'].isin(top_movie_ids)][['movieId', 'title']].copy()\n",
        "    results['predicted_rating'] = [round(user_ratings[i], 4) for i in top_indices]\n",
        "    return results\n",
        "\n",
        "def get_hybrid_recommendations(title, user_id, top_n=10):\n",
        "    content_recs = get_content_recommendations(title, top_n=30)\n",
        "    if 'Error' in content_recs.columns:\n",
        "        return content_recs\n",
        "    if user_id not in user_ids:\n",
        "        return pd.DataFrame({'Error': ['User ID not found.']})\n",
        "\n",
        "    user_idx = list(user_ids).index(user_id)\n",
        "    user_ratings = predicted_ratings[user_idx]\n",
        "\n",
        "    content_recs = content_recs.copy()\n",
        "    content_recs = content_recs[content_recs['movieId'].isin(movie_ids)]\n",
        "    content_recs['predicted_rating'] = content_recs['movieId'].apply(\n",
        "        lambda x: user_ratings[list(movie_ids).get_loc(x)]\n",
        "    )\n",
        "\n",
        "    # Hybrid score: 50% content similarity + 50% collaborative predicted rating\n",
        "    content_recs['hybrid_score'] = (content_recs['score'] + content_recs['predicted_rating']) / 2\n",
        "    return content_recs.sort_values('hybrid_score', ascending=False).head(top_n)[['movieId', 'title', 'hybrid_score']]\n",
        "\n",
        "# ================== Evaluation Functions ==================\n",
        "\n",
        "def evaluate_on_test(test_df, predicted_ratings, user_ids, movie_ids):\n",
        "    y_true, y_pred = [], []\n",
        "    for _, row in test_df.iterrows():\n",
        "        uid, mid, true_rating = row['userId'], row['movieId'], row['rating']\n",
        "        if uid in user_ids and mid in movie_ids:\n",
        "            user_idx = list(user_ids).index(uid)\n",
        "            movie_idx = movie_ids.get_loc(mid)\n",
        "            pred_rating = predicted_ratings[user_idx][movie_idx]\n",
        "            y_true.append(true_rating)\n",
        "            y_pred.append(pred_rating)\n",
        "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    return rmse, mae\n",
        "\n",
        "def predict_content_rating(user_id, movie_id):\n",
        "    if movie_id not in indices.values or user_id not in user_ids:\n",
        "        return None\n",
        "    movie_idx = list(movies['movieId']).index(movie_id)\n",
        "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    user_rated = rating_matrix.loc[user_id]\n",
        "    weighted_sum = 0\n",
        "    sim_total = 0\n",
        "\n",
        "    for idx, score in sim_scores:\n",
        "        sim_movie_id = movies.iloc[idx]['movieId']\n",
        "        if sim_movie_id in rating_matrix.columns and not np.isnan(user_rated.get(sim_movie_id, np.nan)):\n",
        "            rating = user_rated[sim_movie_id]\n",
        "            weighted_sum += score * rating\n",
        "            sim_total += score\n",
        "        if sim_total > 0 and len(user_rated[user_rated > 0]) > 0:\n",
        "            break\n",
        "\n",
        "    return weighted_sum / sim_total if sim_total > 0 else np.nan\n",
        "\n",
        "def predict_hybrid_rating(user_id, movie_id):\n",
        "    collab_rating = None\n",
        "    content_rating = None\n",
        "\n",
        "    if user_id in user_ids and movie_id in movie_ids:\n",
        "        user_idx = list(user_ids).index(user_id)\n",
        "        movie_idx = list(movie_ids).get_loc(movie_id)\n",
        "        collab_rating = predicted_ratings[user_idx][movie_idx]\n",
        "\n",
        "    content_rating = predict_content_rating(user_id, movie_id)\n",
        "\n",
        "    if content_rating is not None and collab_rating is not None:\n",
        "        return (collab_rating + content_rating) / 2\n",
        "    elif collab_rating is not None:\n",
        "        return collab_rating\n",
        "    elif content_rating is not None:\n",
        "        return content_rating\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "def evaluate_model(model_predict_func, test_df):\n",
        "    y_true, y_pred = [], []\n",
        "    for _, row in test_df.iterrows():\n",
        "        uid, mid, true_rating = row['userId'], row['movieId'], row['rating']\n",
        "        pred = model_predict_func(uid, mid)\n",
        "        if pred is not None and not np.isnan(pred):\n",
        "            y_true.append(true_rating)\n",
        "            y_pred.append(pred)\n",
        "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    return rmse, mae\n",
        "\n",
        "def evaluate_top_n(user_id, top_n=10, threshold=4.0):\n",
        "    if user_id not in user_ids:\n",
        "        return None\n",
        "\n",
        "    user_idx = list(user_ids).index(user_id)\n",
        "    actual_ratings = rating_matrix.iloc[user_idx]\n",
        "    predicted_ratings_user = predicted_ratings[user_idx]\n",
        "\n",
        "    actual_relevant = set(actual_ratings[actual_ratings >= threshold].index)\n",
        "    top_indices = predicted_ratings_user.argsort()[::-1][:top_n]\n",
        "    predicted_top_n = set(movie_ids[top_indices])\n",
        "\n",
        "    true_positives = len(actual_relevant & predicted_top_n)\n",
        "    precision = true_positives / len(predicted_top_n) if predicted_top_n else 0\n",
        "    recall = true_positives / len(actual_relevant) if actual_relevant else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "# ================== Streamlit App ==================\n",
        "\n",
        "st.set_page_config(page_title=\"üé¨ Hybrid Movie Recommender\", layout=\"centered\")\n",
        "st.title(\"üé¨ Hybrid Movie Recommendation System\")\n",
        "\n",
        "option = st.selectbox(\"Select recommendation type:\",\n",
        "                      [\"Based on Movie Title\", \"Based on User ID\", \"Hybrid Recommendation\", \"Evaluate System\"])\n",
        "\n",
        "if option == \"Based on Movie Title\":\n",
        "    movie_name = st.text_input(\"Enter movie title:\")\n",
        "    if st.button(\"Get Recommendations\"):\n",
        "        if movie_name:\n",
        "            st.write(f\"Recommendations similar to: **{movie_name}**\")\n",
        "            st.dataframe(get_content_recommendations(movie_name))\n",
        "        else:\n",
        "            st.warning(\"Please enter a movie title.\")\n",
        "\n",
        "elif option == \"Based on User ID\":\n",
        "    user_id = st.number_input(\"Enter user ID:\", min_value=1, step=1)\n",
        "    if st.button(\"Get Recommendations\"):\n",
        "        st.write(f\"Recommendations for User ID: **{user_id}**\")\n",
        "        st.dataframe(get_collab_recommendations(user_id))\n",
        "\n",
        "elif option == \"Hybrid Recommendation\":\n",
        "    user_id = st.number_input(\"Enter user ID:\", min_value=1, step=1, key=\"hybrid_user\")\n",
        "    movie_name = st.text_input(\"Enter movie title:\", key=\"hybrid_title\")\n",
        "    if st.button(\"Get Recommendations\"):\n",
        "        if movie_name:\n",
        "            st.write(f\"Hybrid recommendations for Movie: **{movie_name}**, User ID: **{user_id}**\")\n",
        "            st.dataframe(get_hybrid_recommendations(movie_name, user_id))\n",
        "        else:\n",
        "            st.warning(\"Please enter a movie title.\")\n",
        "\n",
        "elif option == \"Evaluate System\":\n",
        "    st.subheader(\"üîç Evaluation Metrics\")\n",
        "\n",
        "    # Collaborative Filtering\n",
        "    rmse_c, mae_c = evaluate_on_test(test_data, predicted_ratings, user_ids, movie_ids)\n",
        "    st.write(f\"üìà **Collaborative Filtering:**\")\n",
        "    st.write(f\"RMSE: {rmse_c:.4f}, MAE: {mae_c:.4f}\")\n",
        "\n",
        "    # Content-Based\n",
        "    rmse_cb, mae_cb = evaluate_model(predict_content_rating, test_data)\n",
        "    st.write(f\"üìò **Content-Based Filtering:**\")\n",
        "    st.write(f\"RMSE: {rmse_cb:.4f}, MAE: {mae_cb:.4f}\")\n",
        "\n",
        "    # Hybrid\n",
        "    rmse_h, mae_h = evaluate_model(predict_hybrid_rating, test_data)\n",
        "    st.write(f\"üîÄ **Hybrid Model:**\")\n",
        "    st.write(f\"RMSE: {rmse_h:.4f}, MAE: {mae_h:.4f}\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.write(\"üéØ **Top-N Precision/Recall/F1 (sample users):**\")\n",
        "    sample_user_ids = [1, 2, 3]\n",
        "    for uid in sample_user_ids:\n",
        "        metrics = evaluate_top_n(uid)\n",
        "        if metrics:\n",
        "            p, r, f1 = metrics\n",
        "            st.write(f\"User {uid} - Precision: {p:.2f}, Recall: {r:.2f}, F1-Score: {f1:.2f}\")\n",
        "        else:\n",
        "            st.write(f\"User {uid} not found.\")\n"
      ]
    }
  ]
}